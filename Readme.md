# Use dreambooth to generate incomplete sculptural arms
The project focuses on the phenomenon of "Art restoration errors" and uses incomplete sculpture images as a pre-training dreambooth database to generate "outrageous" sculpture images. The reason why I say "outrageous" images is that these sculpture images with complete bodies have changed the specific culture and art style represented by the original sculptures, and the AI methods used now are just fake. The purpose of the project is to critically think about the disrespect of modern absurd aesthetics to traditional aesthetics in art restoration.

The project uses public Github and the Google Colab platform:
source: https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb




### Code Run
When running in google colab, you need to note that because it is running on the website, it may sometimes be unstable. At this time, you need to change the code and run it again.
If it doesn't work, try Test The Trained Model by typing:

```sh
pip install gradio==4.20.1
```
```sh
!pip install --upgrade pydantic
```
```sh
!pip install fastapi
```
```sh
!pip install anyio==3.6.2
```
```sh
!pip cache purge
```
```sh
!pip install cchardet
```

### Code Running Process
![pic01](https://raw.githubusercontent.com/DanyangLi2024/fast-stable-diffusion/80c553bd1dad748b2b401f4f95cd80de80425724/md-pic01.png)
⬆️After getting the .ckpt file after Training, put in Test The Trained Model and start running.

![pic02](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic02.png?raw=true)
⬆️Once the code is running, open this website and adjust these sliders.

### Results of Running the Code
![pic07](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic07.jpg?raw=true)
⬆️While generating the image I noticed that the sculpture generated in txt2img had terrible features and arms. (left image)
After some experimentation, I found that taking the graph generated by txt2img and putting it in img2img would be much better. (right image)

![pic03](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic03.jpg?raw=true)
⬆️The picture on the left is generated directly by txt2img, and the picture on the right is put into img2img after two or more times of processing.

![pic04](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic04.jpg?raw=true)
![pic08](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic08.jpg?raw=true)
⬆️Here 4 images. The images on the left are all generated directly and the ones on the right have the slider CFG turned up.
I have found that the higher the CFG value, the closer the image will be to the textual description, but it can also result in the image becoming unnatural.

![pic05](https://github.com/DanyangLi2024/fast-stable-diffusion/blob/main/md-pic05.jpg?raw=true)
Using dreambooth to generate images of complete sculptures is a good way to get there. However, there are still unnatural situations. As, the project wants to express: thinking critically about contemporary art restoration.



### Special Thanks
Project comes from TheLastBen's Github files, thanks to TheLastBen.
Dreambooth paper : https://dreambooth.github.io/
SD implementation by @XavierXiao : https://github.com/XavierXiao/Dreambooth-Stable-Diffusion

